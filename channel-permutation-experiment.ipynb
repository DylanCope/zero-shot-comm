{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import simplejson\n",
    "\n",
    "EXPERIMENT_FOLDER = \"./experiments/channel_permutation_2\"\n",
    "Path(EXPERIMENT_FOLDER).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.reset_defaults()\n",
    "sns.set()\n",
    "\n",
    "print('Physical Devices:')\n",
    "for dev in tf.config.list_physical_devices():\n",
    "    print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zscomm.agent import Agent\n",
    "from zscomm.comm_channel import CommChannel\n",
    "from zscomm.synth_teacher import SyntheticTeacher\n",
    "from zscomm.data import *\n",
    "from zscomm.play_game import *\n",
    "from zscomm.loss import *\n",
    "from zscomm.experiment import Experiment\n",
    "from zscomm.meta_experiment import *\n",
    "from zscomm.plot_game import plot_game\n",
    "from zscomm.analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "BATCH_SIZE = 32\n",
    "CHANNEL_SIZE = 5\n",
    "\n",
    "TRAIN_DATA, TEST_DATA = get_simple_card_data(num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_batch():\n",
    "    return generate_batch(TRAIN_DATA,\n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_classes=NUM_CLASSES)\n",
    "\n",
    "\n",
    "def generate_test_batch():\n",
    "    return generate_batch(TEST_DATA,\n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_message_permutation_experiment(channel_size=5, **exp_kwargs):\n",
    "    \n",
    "#     agent = Agent(channel_size, NUM_CLASSES)\n",
    "\n",
    "#     play_params =  {\n",
    "#         'channel_size': channel_size,\n",
    "#         'p_mutate': 0,\n",
    "#         'message_permutation': True,\n",
    "#     }\n",
    "    \n",
    "#     return Experiment(\n",
    "#         generate_train_batch, generate_test_batch,\n",
    "#         play_params=play_params, \n",
    "#         student=agent,\n",
    "#         teacher=agent,\n",
    "#         loss_fn=complete_loss_fn,\n",
    "#         **exp_kwargs\n",
    "#     )\n",
    "\n",
    "\n",
    "def create_message_permutation_separate_experiment(channel_size=5, epochs=150, **exp_kwargs):\n",
    "    \n",
    "    agent = Agent(channel_size, NUM_CLASSES)\n",
    "\n",
    "    play_params =  {\n",
    "        'channel_size': channel_size,\n",
    "        'p_mutate': 0,\n",
    "        'message_permutation': True,\n",
    "        'channel_temp': 1.0,\n",
    "    }\n",
    "    \n",
    "    beta = 10\n",
    "    def teacher_loss_fn(o, t):\n",
    "        return beta * student_pred_matches_test_class(o, t)\n",
    "    \n",
    "    return Experiment(\n",
    "        generate_train_batch, generate_test_batch,\n",
    "        play_params=play_params, \n",
    "        student=agent,\n",
    "        teacher=agent,\n",
    "        student_loss_fn=student_pred_matches_test_class,\n",
    "        teacher_loss_fn=teacher_loss_fn,\n",
    "        max_epochs=epochs,\n",
    "        lr=1e-2,\n",
    "        step_print_freq=10,\n",
    "        **exp_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def create_channel_permutation_experiment(channel_size=5, epochs=200, **exp_kwargs):\n",
    "    \n",
    "    agent = Agent(channel_size, NUM_CLASSES)\n",
    "\n",
    "    start_temp = 10\n",
    "    end_temp = 0.1\n",
    "    temp_anneal_end_epoch = 200\n",
    "    a = -np.log(end_temp / start_temp) / temp_anneal_end_epoch\n",
    "    \n",
    "    def play_params(epoch):\n",
    "        if epoch < temp_anneal_end_epoch:\n",
    "            channel_temp = float(start_temp * np.exp(-a*epoch))\n",
    "        else:\n",
    "            channel_temp = end_temp\n",
    "        \n",
    "        return {\n",
    "            'channel_size': channel_size,\n",
    "            'p_mutate': 0,\n",
    "            'message_permutation': True,\n",
    "            'channel_temp': channel_temp,\n",
    "        }\n",
    "    \n",
    "    return Experiment(\n",
    "        generate_train_batch, generate_test_batch,\n",
    "        play_params=play_params, \n",
    "        student=agent,\n",
    "        teacher=agent,\n",
    "        loss_fn=student_pred_matches_test_class,\n",
    "        max_epochs=epochs,\n",
    "        lr=1e-2,\n",
    "        step_print_freq=10,\n",
    "        **exp_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_experiment = MetaExperiment(\n",
    "    create_experiment_fn=create_channel_permutation_experiment,\n",
    "    num_experiments=6,\n",
    "    export_location=EXPERIMENT_FOLDER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_played, _ = permutation_experiment.experiments[0]['experiment'].run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher = Agent(CHANNEL_SIZE, NUM_CLASSES)\n",
    "# student = Agent(CHANNEL_SIZE, NUM_CLASSES)\n",
    "\n",
    "# exp = permutation_experiment.experiments[0]['experiment']\n",
    "\n",
    "# inputs, targets = generate_train_batch()\n",
    "\n",
    "# with tf.GradientTape(persistent=True) as tape:\n",
    "#     outputs = play_game(inputs, teacher, student, \n",
    "#                         training=True, \n",
    "#                         **exp.get_play_params())\n",
    "\n",
    "#     loss = student_pred_matches_test_class(outputs, targets)\n",
    "    \n",
    "# teacher_grads = tape.gradient(loss, teacher.trainable_variables)\n",
    "# student_grads = tape.gradient(loss, student.trainable_variables)\n",
    "\n",
    "# for v, g in zip(teacher.trainable_variables, teacher_grads):\n",
    "#     print(f'{v.name} teacher grad norm: {tf.reduce_sum(g**2)**0.5}')\n",
    "\n",
    "# print()\n",
    "\n",
    "# for v, g in zip(student.trainable_variables, student_grads):\n",
    "#     print(f'{v.name} student grad norm: {tf.reduce_sum(g**2)**0.5}')\n",
    "    \n",
    "# # agent/dense_200/kernel:0 teacher grad norm: 0.004447852727025747\n",
    "# # agent/dense_200/bias:0 teacher grad norm: 0.004131803754717112\n",
    "# # agent/lstm_100/kernel:0 teacher grad norm: 0.00819376204162836\n",
    "# # agent/lstm_100/recurrent_kernel:0 teacher grad norm: 0.001391303027048707\n",
    "# # agent/lstm_100/bias:0 teacher grad norm: 0.008151191286742687\n",
    "# # agent/dense_201/kernel:0 teacher grad norm: 0.004122724756598473\n",
    "# # agent/dense_201/bias:0 teacher grad norm: 0.01262927521020174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = permutation_experiment.experiments[0]['experiment']\n",
    "# inputs, targets = generate_train_batch()\n",
    "# outputs = play_game(inputs, exp.teacher, exp.student, \n",
    "#                     training=True, \n",
    "#                     **exp.get_play_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_game(inputs, outputs, targets, select_batch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"agent\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1664      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  520       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 51,592\n",
      "Trainable params: 51,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "permutation_experiment.experiments[0]['experiment'].student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running meta_experiment...\n",
      "Running experiment 0 (0/6 complete):\n",
      "Running experiment...\n",
      "Run config:\n",
      " {'name': 'experiment', 'max_epochs': 200, 'steps_per_epoch': 50, 'epochs_optimised': 93, 'play_params': {'channel_size': 5, 'p_mutate': 0, 'message_permutation': True, 'channel_temp': 1.1748975549395295}, 'test_freq': 5, 'test_steps': 25, 'optimiser_config': {'name': 'RMSprop', 'learning_rate': 0.009999999776482582, 'decay': 0.0, 'rho': 0.8999999761581421, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}, 'optimise_agents_separately': False, 'loss_fn': 'student_pred_matches_test_class'}\n",
      "Epoch 0, Time Taken (mm:ss): 0:7, Mean Loss: 1.1\n",
      "Test Loss: 1.1, Ground Truth F1-Score: 0.344, Student Error: 1.099, Teacher Error: 1.631, Protocol Diversity: 0.358,\n",
      "Epoch 1, Time Taken (mm:ss): 0:8, Mean Loss: 1.103\n",
      "Epoch 2, Time Taken (mm:ss): 0:10, Mean Loss: 1.101\n",
      "Epoch 3, Time Taken (mm:ss): 0:7, Mean Loss: 1.101\n",
      "Epoch 4, Time Taken (mm:ss): 0:6, Mean Loss: 1.101\n",
      "Epoch 5, Time Taken (mm:ss): 0:6, Mean Loss: 1.095\n",
      "Test Loss: 1.107, Ground Truth F1-Score: 0.319, Student Error: 1.109, Teacher Error: 1.711, Protocol Diversity: 0.446,\n",
      "Epoch 6, Time Taken (mm:ss): 0:6, Mean Loss: 1.103\n",
      "Epoch 7, Time Taken (mm:ss): 0:6, Mean Loss: 1.096\n",
      "Epoch 8, Time Taken (mm:ss): 0:6, Mean Loss: 1.097\n",
      "Epoch 9, Time Taken (mm:ss): 0:8, Mean Loss: 1.101\n",
      "Epoch 10, Time Taken (mm:ss): 0:6, Mean Loss: 1.1\n",
      "Test Loss: 1.1, Ground Truth F1-Score: 0.318, Student Error: 1.099, Teacher Error: 1.661, Protocol Diversity: 0.333,\n",
      "Epoch 11, Time Taken (mm:ss): 0:6, Mean Loss: 1.096\n",
      "Epoch 12, Time Taken (mm:ss): 0:6, Mean Loss: 1.101\n",
      "Epoch 13, Time Taken (mm:ss): 0:7, Mean Loss: 1.088\n",
      "Epoch 14, Time Taken (mm:ss): 0:7, Mean Loss: 1.1\n",
      "Epoch 15, Time Taken (mm:ss): 0:7, Mean Loss: 1.104\n",
      "Test Loss: 1.098, Ground Truth F1-Score: 0.343, Student Error: 1.099, Teacher Error: 1.993, Protocol Diversity: 0.333,\n",
      "Epoch 16, Time Taken (mm:ss): 0:7, Mean Loss: 0.868\n",
      "Epoch 17, Time Taken (mm:ss): 0:8, Mean Loss: 0.324\n",
      "Epoch 18, Time Taken (mm:ss): 0:8, Mean Loss: 0.058\n",
      "Epoch 19, Time Taken (mm:ss): 0:8, Mean Loss: 0.142\n",
      "Epoch 20, Time Taken (mm:ss): 0:7, Mean Loss: 0.038\n",
      "Test Loss: 6.239, Ground Truth F1-Score: 0.343, Student Error: 5.061, Teacher Error: 7.894, Protocol Diversity: 0.416,\n",
      "Epoch 21, Time Taken (mm:ss): 0:7, Mean Loss: 0.011\n",
      "Epoch 22, Time Taken (mm:ss): 0:7, Mean Loss: 0.037\n",
      "Epoch 23, Time Taken (mm:ss): 0:7, Mean Loss: 0.001\n",
      "Epoch 24, Time Taken (mm:ss): 0:7, Mean Loss: 0.082\n",
      "Epoch 25, Time Taken (mm:ss): 0:7, Mean Loss: 0.001\n",
      "Test Loss: 6.498, Ground Truth F1-Score: 0.343, Student Error: 5.652, Teacher Error: 8.231, Protocol Diversity: 0.417,\n",
      "Epoch 26, Time Taken (mm:ss): 0:7, Mean Loss: 0.054\n",
      "Epoch 27, Time Taken (mm:ss): 0:7, Mean Loss: 0.002\n",
      "Epoch 28, Time Taken (mm:ss): 0:7, Mean Loss: 0.016\n",
      "Epoch 29, Time Taken (mm:ss): 0:7, Mean Loss: 0.182\n",
      "Epoch 30, Time Taken (mm:ss): 0:7, Mean Loss: 0.005\n",
      "Test Loss: 5.946, Ground Truth F1-Score: 0.352, Student Error: 5.313, Teacher Error: 8.262, Protocol Diversity: 0.353,\n",
      "Epoch 31, Time Taken (mm:ss): 0:7, Mean Loss: 0.018\n",
      "Epoch 32, Time Taken (mm:ss): 0:8, Mean Loss: 0.002\n",
      "Epoch 33, Time Taken (mm:ss): 0:8, Mean Loss: 0.001\n",
      "Epoch 34, Time Taken (mm:ss): 0:7, Mean Loss: 0.06\n",
      "Epoch 35, Time Taken (mm:ss): 0:7, Mean Loss: 0.004\n",
      "Test Loss: 7.438, Ground Truth F1-Score: 0.329, Student Error: 6.746, Teacher Error: 8.013, Protocol Diversity: 0.389,\n",
      "Epoch 36, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Epoch 37, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Epoch 38, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Epoch 39, Time Taken (mm:ss): 0:6, Mean Loss: 0.026\n",
      "Epoch 40, Time Taken (mm:ss): 0:6, Mean Loss: 0.094\n",
      "Test Loss: 7.573, Ground Truth F1-Score: 0.315, Student Error: 7.089, Teacher Error: 7.631, Protocol Diversity: 0.352,\n",
      "Epoch 41, Time Taken (mm:ss): 0:6, Mean Loss: 0.02\n",
      "Epoch 42, Time Taken (mm:ss): 0:6, Mean Loss: 0.017\n",
      "Epoch 43, Time Taken (mm:ss): 0:6, Mean Loss: 0.053\n",
      "Epoch 44, Time Taken (mm:ss): 0:7, Mean Loss: 0.084\n",
      "Epoch 45, Time Taken (mm:ss): 0:6, Mean Loss: 0.078\n",
      "Test Loss: 6.135, Ground Truth F1-Score: 0.338, Student Error: 5.256, Teacher Error: 7.481, Protocol Diversity: 0.5,\n",
      "Epoch 46, Time Taken (mm:ss): 0:6, Mean Loss: 0.031\n",
      "Epoch 47, Time Taken (mm:ss): 0:6, Mean Loss: 0.006\n",
      "Epoch 48, Time Taken (mm:ss): 0:8, Mean Loss: 0.004\n",
      "Epoch 49, Time Taken (mm:ss): 0:8, Mean Loss: 0.015\n",
      "Epoch 50, Time Taken (mm:ss): 0:7, Mean Loss: 0.008\n",
      "Test Loss: 7.446, Ground Truth F1-Score: 0.324, Student Error: 5.694, Teacher Error: 7.367, Protocol Diversity: 0.5,\n",
      "Epoch 51, Time Taken (mm:ss): 0:6, Mean Loss: 0.002\n",
      "Epoch 52, Time Taken (mm:ss): 0:6, Mean Loss: 0.019\n",
      "Epoch 53, Time Taken (mm:ss): 0:6, Mean Loss: 0.004\n",
      "Epoch 54, Time Taken (mm:ss): 0:6, Mean Loss: 0.14\n",
      "Epoch 55, Time Taken (mm:ss): 0:6, Mean Loss: 0.022\n",
      "Test Loss: 5.666, Ground Truth F1-Score: 0.321, Student Error: 5.623, Teacher Error: 7.64, Protocol Diversity: 0.5,\n",
      "Epoch 56, Time Taken (mm:ss): 0:6, Mean Loss: 0.036\n",
      "Epoch 57, Time Taken (mm:ss): 0:6, Mean Loss: 0.012\n",
      "Epoch 58, Time Taken (mm:ss): 0:6, Mean Loss: 0.002\n",
      "Epoch 59, Time Taken (mm:ss): 0:8, Mean Loss: 0.014\n",
      "Epoch 60, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Test Loss: 8.299, Ground Truth F1-Score: 0.347, Student Error: 6.969, Teacher Error: 8.153, Protocol Diversity: 0.4,\n",
      "Epoch 61, Time Taken (mm:ss): 0:6, Mean Loss: 0.011\n",
      "Epoch 62, Time Taken (mm:ss): 0:6, Mean Loss: 0.003\n",
      "Epoch 63, Time Taken (mm:ss): 0:6, Mean Loss: 0.0\n",
      "Epoch 64, Time Taken (mm:ss): 0:8, Mean Loss: 0.001\n",
      "Epoch 65, Time Taken (mm:ss): 0:8, Mean Loss: 0.001\n",
      "Test Loss: 8.68, Ground Truth F1-Score: 0.344, Student Error: 6.125, Teacher Error: 8.35, Protocol Diversity: 0.787,\n",
      "Epoch 66, Time Taken (mm:ss): 0:7, Mean Loss: 0.001\n",
      "Epoch 67, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Epoch 68, Time Taken (mm:ss): 0:6, Mean Loss: 0.035\n",
      "Epoch 69, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Epoch 70, Time Taken (mm:ss): 0:6, Mean Loss: 0.001\n",
      "Test Loss: 6.611, Ground Truth F1-Score: 0.36, Student Error: 5.248, Teacher Error: 8.577, Protocol Diversity: 0.633,\n",
      "Epoch 71, Time Taken (mm:ss): 0:6, Mean Loss: 0.016\n",
      "Epoch 72, Time Taken (mm:ss): 0:6, Mean Loss: 0.053\n",
      "Epoch 73, Time Taken (mm:ss): 0:6, Mean Loss: 0.0\n",
      "Epoch 74, Time Taken (mm:ss): 0:6, Mean Loss: 0.136\n",
      "Epoch 75, Time Taken (mm:ss): 0:6, Mean Loss: 0.064\n",
      "Test Loss: 6.031, Ground Truth F1-Score: 0.309, Student Error: 3.056, Teacher Error: 8.029, Protocol Diversity: 0.566,\n",
      "Epoch 76, Time Taken (mm:ss): 0:6, Mean Loss: 0.016\n",
      "Epoch 77, Time Taken (mm:ss): 0:7, Mean Loss: 0.002\n",
      "Epoch 78, Time Taken (mm:ss): 0:6, Mean Loss: 0.071\n",
      "Epoch 79, Time Taken (mm:ss): 0:6, Mean Loss: 0.044\n",
      "Epoch 80, Time Taken (mm:ss): 0:8, Mean Loss: 0.062\n",
      "Test Loss: 6.923, Ground Truth F1-Score: 0.346, Student Error: 5.978, Teacher Error: 8.4, Protocol Diversity: 0.47,\n",
      "Epoch 81, Time Taken (mm:ss): 0:8, Mean Loss: 0.003\n",
      "Epoch 82, Time Taken (mm:ss): 0:7, Mean Loss: 0.005\n",
      "Epoch 83, Time Taken (mm:ss): 0:6, Mean Loss: 0.008\n",
      "Epoch 84, Time Taken (mm:ss): 0:7, Mean Loss: 0.11\n",
      "Epoch 85, Time Taken (mm:ss): 0:6, Mean Loss: 0.064\n",
      "Test Loss: 5.304, Ground Truth F1-Score: 0.356, Student Error: 4.086, Teacher Error: 8.236, Protocol Diversity: 0.719,\n",
      "Epoch 86, Time Taken (mm:ss): 0:7, Mean Loss: 0.095\n",
      "Epoch 87, Time Taken (mm:ss): 0:6, Mean Loss: 0.004\n",
      "Epoch 88, Time Taken (mm:ss): 0:6, Mean Loss: 0.154\n",
      "Epoch 89, Time Taken (mm:ss): 0:6, Mean Loss: 0.009\n",
      "Epoch 90, Time Taken (mm:ss): 0:6, Mean Loss: 0.003\n",
      "Test Loss: 5.158, Ground Truth F1-Score: 0.351, Student Error: 4.329, Teacher Error: 7.761, Protocol Diversity: 0.773,\n",
      "Epoch 91, Time Taken (mm:ss): 0:6, Mean Loss: 0.055\n",
      "Epoch 92, Time Taken (mm:ss): 0:7, Mean Loss: 0.063\n",
      "Epoch 93, 60.0% complete, Loss: 0.0578\n"
     ]
    }
   ],
   "source": [
    "permutation_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in permutation_experiment.experiments:\n",
    "    if item['status'] == 'Complete':\n",
    "        total_time = sum([\n",
    "            x['seconds_taken']\n",
    "            for x in item['experiment'].training_history\n",
    "        ])\n",
    "        print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_experiment.experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_permutation_experiment(path):\n",
    "    \n",
    "    config = json.load((path / 'config.json').open(mode='r'))\n",
    "    results = json.load((path / 'results.json').open(mode='r'))\n",
    "    history = json.load((path / 'training_history.json').open(mode='r'))\n",
    "    \n",
    "    agent = Agent(config['play_params']['channel_size'], NUM_CLASSES)\n",
    "    agent.load_weights(str(path / 'agent_weights'))\n",
    "    \n",
    "    config['loss_fn'] = student_pred_matches_test_class\n",
    "    \n",
    "    kwargs = {\n",
    "        k: v for k, v in config.items()\n",
    "        if k not in ['epochs_optimised', 'optimiser_config']\n",
    "    }\n",
    "    experiment = Experiment(\n",
    "        generate_train_batch, generate_test_batch,\n",
    "        student=agent,\n",
    "        teacher=agent,\n",
    "        **kwargs\n",
    "    )\n",
    "    experiment.epoch = config['epochs_optimised']\n",
    "    experiment.training_history = history\n",
    "    experiment.results = results\n",
    "    \n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for path in Path(EXPERIMENT_FOLDER).glob('*'):\n",
    "    if not path.is_file():\n",
    "        exp = load_channel_permutation_experiment(path)\n",
    "        experiments.append(exp)\n",
    "        print('Loaded experiment from:', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def did_converge_to_global_optima(experiment):\n",
    "    return experiment.results['mean_ground_truth_f1'] > 0.9\n",
    "\n",
    "def did_converge_to_local_optima(experiment):\n",
    "    return 0.9 > experiment.results['mean_ground_truth_f1'] > 0.6\n",
    "\n",
    "def get_category(experiment):\n",
    "    if did_converge_to_global_optima(experiment):\n",
    "        return 'Coverged to Global Optima'\n",
    "    if did_converge_to_local_optima(experiment):\n",
    "        return 'Coverged to Local Optima'\n",
    "    return 'Did Not Converge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'Epoch': epoch,\n",
    "        'Loss': train_item['loss'],\n",
    "        'Experiment': f\"Run {index}\",\n",
    "        'Category': get_category(experiment)\n",
    "    }\n",
    "    for index, experiment in enumerate(experiments)\n",
    "    for epoch, train_item in enumerate(experiment.training_history)\n",
    "])\n",
    "df = df[df['Category'] != 'Did Not Converge']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x='Epoch', y='Loss', hue='Category', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'Epoch': epoch,\n",
    "        'Performance': train_item['test_metrics']['mean_ground_truth_f1'],\n",
    "        'Protocol Diversity': train_item['test_metrics']['mean_protocol_diversity'],\n",
    "        'Experiment': f\"Run {index}\",\n",
    "        'Category': get_category(experiment)\n",
    "    }\n",
    "    for index, experiment in enumerate(experiments)\n",
    "    for epoch, train_item in enumerate(experiment.training_history)\n",
    "    if 'test_metrics' in train_item\n",
    "])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].set_title('Test Performance')\n",
    "axs[1].set_title('Protocol Diversity')\n",
    "\n",
    "sns.lineplot(x='Epoch', y='Performance', hue='Category', data=df, ax=axs[0]);\n",
    "sns.lineplot(x='Epoch', y='Protocol Diversity', hue='Category', data=df, ax=axs[1]);\n",
    "for ax in axs:\n",
    "    ax.set_ylim([0, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_played, _ = experiments[4].run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     inputs, targets, outputs = games_played[i]\n",
    "#     plot_game(inputs, outputs, targets, select_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_class_message_map = create_mean_class_message_map(games_played)\n",
    "sns.heatmap(mean_class_message_map, vmin=0, vmax=1);\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Symbol')\n",
    "plt.title('Communication Protocol')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = compute_confusion_matrix(games_played)\n",
    "sns.heatmap(conf_matrix, annot=True, vmin=0, vmax=1)\n",
    "plt.title('Ground Truth Confusion Matrix')\n",
    "plt.ylabel('Predicted Class')\n",
    "plt.xlabel('Actual Class');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
